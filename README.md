# NLP-resampling-techniques-using-imbalanced-learn


About imbalance learn.
The project started in August 2014 by Fernando Nogueira and focused on SMOTE implementation. Together with Guillaume Lemaitre, Dayvid Victor, and Christos Aridas, additional under-sampling and over-sampling methods have been implemented as well as major changes in the API to be fully compatible with scikit-learn.

Problem statement regarding imbalanced data sets:

The learning phase and the subsequent prediction of machine learning algorithms can be affected by the 
problem of imbalanced data set. The balancing issue corresponds to the difference of the number of samples 
in the different classes. We illustrate the effect of training a linear SVM classifier with different level
of class balancing.

![alt text](https://imbalanced-learn.readthedocs.io/en/stable/_images/sphx_glr_plot_comparison_over_sampling_0011.png)


For more details visit:

https://imbalanced-learn.readthedocs.io/en/stable/index.html
